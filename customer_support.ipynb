{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221025fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch scikit-learn pandas fastapi uvicorn \"python-multipart\" \"uvicorn[standard]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import os\n",
    "\n",
    "# --- 1. Data Simulation ---\n",
    "# In a real project, replace this with your actual dataset loading.\n",
    "# The dataset should have at least two columns: 'text' (the ticket) and 'label' (the category).\n",
    "def generate_synthetic_data(num_samples=1000):\n",
    "    data = {\n",
    "        'text': [\n",
    "            \"I need help with my recent bill. It seems too high.\",\n",
    "            \"My service is not working. The internet is down.\",\n",
    "            \"I would like to request a refund for my order #12345.\",\n",
    "            \"My account is locked and I can't log in.\",\n",
    "            \"How do I reset my password?\",\n",
    "            \"Can you help me with a billing inquiry?\",\n",
    "            \"There's a bug in your software. It keeps crashing.\",\n",
    "            \"I want to know the status of my refund.\",\n",
    "            \"The app is slow on my phone.\",\n",
    "            \"Please cancel my subscription.\",\n",
    "        ] * (num_samples // 10),\n",
    "        'label': [\n",
    "            'Billing',\n",
    "            'Technical Support',\n",
    "            'Refunds',\n",
    "            'Account Access',\n",
    "            'Account Access',\n",
    "            'Billing',\n",
    "            'Technical Support',\n",
    "            'Refunds',\n",
    "            'Technical Support',\n",
    "            'Billing',\n",
    "        ] * (num_samples // 10)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "\n",
    "class SupportTicketDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def prepare_data(df):\n",
    "    labels = df['label'].unique().tolist()\n",
    "    label_map = {label: i for i, label in enumerate(labels)}\n",
    "    df['label_id'] = df['label'].map(label_map)\n",
    "\n",
    "    # Split data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        df['text'].tolist(),\n",
    "        df['label_id'].tolist(),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=df['label_id']\n",
    "    )\n",
    "    \n",
    "    # BERT Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "    \n",
    "    train_dataset = SupportTicketDataset(train_encodings, train_labels)\n",
    "    val_dataset = SupportTicketDataset(val_encodings, val_labels)\n",
    "    \n",
    "    return train_dataset, val_dataset, label_map, tokenizer\n",
    "\n",
    "# --- 3. Model Training ---\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "def train_bert_model(train_dataset, val_dataset, label_map):\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    model_path = \"./bert_classifier\"\n",
    "    model.save_pretrained(model_path)\n",
    "    print(f\"BERT model saved to {model_path}\")\n",
    "    \n",
    "    # Save the label mapping for inference\n",
    "    labels = {v: k for k, v in label_map.items()}\n",
    "    pd.Series(labels).to_json(os.path.join(model_path, 'labels.json'))\n",
    "    \n",
    "    return trainer, label_map\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_tickets = generate_synthetic_data()\n",
    "    train_ds, val_ds, label_mapping, tokenizer = prepare_data(df_tickets)\n",
    "    \n",
    "    # Train the model\n",
    "    trainer, _ = train_bert_model(train_ds, val_ds, label_mapping)\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    results = trainer.evaluate()\n",
    "    print(\"\\nFinal Evaluation Results:\")\n",
    "    print(results)\n",
    "    \n",
    "    # The output will show accuracy and F1-score as requested in the prompt.\n",
    "    # The reduction in errors is a direct consequence of the accuracy gain over a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import f1_score\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- 1. Knowledge Base Simulation ---\n",
    "def create_knowledge_base():\n",
    "    return [\n",
    "        \"To reset your password, go to the login page and click 'Forgot Password'. Follow the instructions sent to your email.\",\n",
    "        \"Billing inquiries can be handled by our billing department. Please provide your account number for faster service.\",\n",
    "        \"For technical issues, first try restarting your device. If the problem persists, please describe the issue in detail.\",\n",
    "        \"Refunds are processed within 5-7 business days after the request has been approved. You will receive an email confirmation.\",\n",
    "        \"Your account might be locked due to multiple failed login attempts. Please wait 15 minutes or contact support.\",\n",
    "        \"To change your subscription, log in to your account, navigate to 'Manage Subscription', and select a new plan.\",\n",
    "        \"We are sorry to hear you're experiencing a bug. Our engineers are working on a fix for this issue.\",\n",
    "    ]\n",
    "\n",
    "# --- 2. RAG System Components ---\n",
    "class RAGSystem:\n",
    "    def __init__(self, knowledge_base):\n",
    "        # Using a Sentence Transformer to create embeddings\n",
    "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.knowledge_base = knowledge_base\n",
    "        self.embeddings = self.encoder.encode(knowledge_base)\n",
    "        \n",
    "        # Build a FAISS index for efficient similarity search\n",
    "        self.index = faiss.IndexFlatL2(self.embeddings.shape[1])\n",
    "        self.index.add(np.array(self.embeddings).astype('float32'))\n",
    "        \n",
    "        # Using a small open-source LLM for demonstration\n",
    "        # In a real project, you might use a more powerful model like Llama 3 or GPT-4 via an API\n",
    "        model_name = \"distilgpt2\"\n",
    "        self.llm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.llm_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        \n",
    "        # NOTE: For this example, we'll use a local LLM. A more common approach is using an API from a provider like OpenAI.\n",
    "        # client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "    def retrieve(self, query, k=1):\n",
    "        \"\"\"Finds the most relevant document(s) from the knowledge base.\"\"\"\n",
    "        query_embedding = self.encoder.encode([query])\n",
    "        D, I = self.index.search(np.array(query_embedding).astype('float32'), k)\n",
    "        return [self.knowledge_base[i] for i in I[0]]\n",
    "\n",
    "    def generate_response(self, query, context):\n",
    "        \"\"\"Generates a response using the LLM and the retrieved context.\"\"\"\n",
    "        # This is the RAG prompt template\n",
    "        prompt = f\"Use the following information to draft a helpful customer support reply:\\n\\nContext: {context}\\n\\nCustomer inquiry: {query}\\n\\nReply:\"\n",
    "        \n",
    "        inputs = self.llm_tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n",
    "        \n",
    "        # Reduce inference time by generating a shorter response for this demo\n",
    "        outputs = self.llm_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=self.llm_tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        response = self.llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the generated reply portion\n",
    "        generated_reply = response.split(\"Reply:\")[1].strip()\n",
    "        \n",
    "        return generated_reply\n",
    "\n",
    "    def auto_draft_reply(self, customer_query):\n",
    "        retrieved_context = self.retrieve(customer_query)\n",
    "        reply = self.generate_response(customer_query, retrieved_context)\n",
    "        return reply\n",
    "\n",
    "# --- 3. Evaluation ---\n",
    "# F1-score for generative models is a tricky metric to measure automatically.\n",
    "# It often involves comparing the generated response to a reference response.\n",
    "# A more robust approach uses an LLM-as-a-judge framework, but for this demo,\n",
    "# we'll use a simple token-level F1-score comparison.\n",
    "\n",
    "def evaluate_f1_score(predicted, reference):\n",
    "    pred_tokens = predicted.lower().split()\n",
    "    ref_tokens = reference.lower().split()\n",
    "    \n",
    "    # Simple F1-score calculation (can be misleading for text generation)\n",
    "    common_tokens = set(pred_tokens) & set(ref_tokens)\n",
    "    if not common_tokens:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(ref_tokens)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kb = create_knowledge_base()\n",
    "    rag = RAGSystem(kb)\n",
    "    \n",
    "    # Test cases with reference answers\n",
    "    test_cases = [\n",
    "        {\n",
    "            'query': \"My account is locked. How do I unlock it?\",\n",
    "            'reference_reply': \"Your account is likely locked due to too many failed login attempts. Please wait 15 minutes or contact support for further assistance.\"\n",
    "        },\n",
    "        {\n",
    "            'query': \"I want to get a refund for my purchase.\",\n",
    "            'reference_reply': \"Refunds are typically processed within 5-7 business days after the request is approved. You will get an email notification once it's complete.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    print(\"--- RAG Reply Auto-Drafting Demo ---\")\n",
    "    for case in test_cases:\n",
    "        query = case['query']\n",
    "        reference = case['reference_reply']\n",
    "        \n",
    "        # Auto-draft the reply\n",
    "        generated_reply = rag.auto_draft_reply(query)\n",
    "        \n",
    "        # Calculate F1-score\n",
    "        f1 = evaluate_f1_score(generated_reply, reference)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Reference Reply: {reference}\")\n",
    "        print(f\"Auto-Drafted Reply: {generated_reply}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        \n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    print(f\"\\nAverage F1-Score: {avg_f1:.4f}\")\n",
    "    # Note: A real-world F1-score of 90% is highly difficult to achieve on diverse data.\n",
    "    # The prompt's 90% F1-score likely refers to a human-in-the-loop evaluation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24510b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import json\n",
    "import uvicorn\n",
    "from starlette.responses import JSONResponse\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Model Paths ---\n",
    "BERT_MODEL_PATH = \"./bert_classifier\"\n",
    "RAG_MODEL_PATH = \"./rag_system\"  # Placeholder\n",
    "\n",
    "# --- API Initialization ---\n",
    "app = FastAPI(\n",
    "    title=\"Customer Support Automation API\",\n",
    "    description=\"BERT for ticket classification & RAG for reply generation.\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# --- Load BERT Model ---\n",
    "try:\n",
    "    logger.info(\"Loading BERT model for classification...\")\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH)\n",
    "    bert_model = BertForSequenceClassification.from_pretrained(BERT_MODEL_PATH)\n",
    "    with open(os.path.join(BERT_MODEL_PATH, 'labels.json'), 'r') as f:\n",
    "        label_map = {v: k for k, v in json.load(f).items()}\n",
    "    logger.info(\"BERT model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading BERT model: {e}\")\n",
    "    bert_model = None\n",
    "\n",
    "# --- Placeholder for RAG system (as it's more complex to load) ---\n",
    "# In a real app, you would load the RAGSystem class here.\n",
    "# For this demo, we'll implement a simple, stateless version.\n",
    "class RAGReply:\n",
    "    def __init__(self):\n",
    "        # Placeholder\n",
    "        pass\n",
    "    \n",
    "    def auto_draft_reply(self, query):\n",
    "        if \"billing\" in query.lower():\n",
    "            return \"For billing inquiries, please provide your account details.\"\n",
    "        elif \"refund\" in query.lower():\n",
    "            return \"Refunds are processed within 5-7 business days.\"\n",
    "        else:\n",
    "            return \"We are reviewing your request and will get back to you shortly.\"\n",
    "\n",
    "rag_replies = RAGReply()\n",
    "\n",
    "\n",
    "# --- API Models for Input/Output ---\n",
    "class TicketInput(BaseModel):\n",
    "    ticket_text: str\n",
    "\n",
    "class ClassificationOutput(BaseModel):\n",
    "    predicted_class: str\n",
    "    confidence: float\n",
    "\n",
    "class ReplyOutput(BaseModel):\n",
    "    drafted_reply: str\n",
    "\n",
    "# --- Endpoints ---\n",
    "@app.get(\"/\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/classify\", response_model=ClassificationOutput)\n",
    "def classify_ticket(ticket: TicketInput):\n",
    "    if not bert_model:\n",
    "        return JSONResponse(\n",
    "            status_code=500,\n",
    "            content={\"message\": \"BERT model not loaded. Check server logs.\"}\n",
    "        )\n",
    "        \n",
    "    try:\n",
    "        # Inference\n",
    "        inputs = bert_tokenizer(ticket.ticket_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            predicted_class_id = torch.argmax(probabilities).item()\n",
    "            confidence = probabilities[0][predicted_class_id].item()\n",
    "            \n",
    "            predicted_label = label_map[predicted_class_id]\n",
    "            \n",
    "        return {\n",
    "            \"predicted_class\": predicted_label,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during classification: {e}\")\n",
    "        return JSONResponse(\n",
    "            status_code=500,\n",
    "            content={\"message\": \"Internal server error during classification.\"}\n",
    "        )\n",
    "\n",
    "@app.post(\"/draft_reply\", response_model=ReplyOutput)\n",
    "def draft_reply(ticket: TicketInput):\n",
    "    try:\n",
    "        drafted_reply = rag_replies.auto_draft_reply(ticket.ticket_text)\n",
    "        return {\"drafted_reply\": drafted_reply}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during reply drafting: {e}\")\n",
    "        return JSONResponse(\n",
    "            status_code=500,\n",
    "            content={\"message\": \"Internal server error during reply drafting.\"}\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set the working directory in the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies (optional, but good practice)\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy the requirements file into the working directory\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Install the dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy the application code into the container\n",
    "COPY . .\n",
    "\n",
    "# Expose the port the app runs on\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run the application using Uvicorn\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0872c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
